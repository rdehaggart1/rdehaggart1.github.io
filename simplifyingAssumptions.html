<!DOCTYPE HTML>
<html>
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link href="StyleSheet.css" rel="stylesheet">
		
		<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
		<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
		
	</head>
	<body>
		<div class = "sidenav">
			<a style="font-weight:bold;color:orange;">Navigation</a>
			<HR class = "orangeRow">
			<a href = "introduction.html">Introduction</a>
			<a href = "whatIsASignal.html">What is a Signal?</a>
			<a href = "simplifyingAssumptions.html">Simplifying Assumptions</a>
			<a href = "usefulOnlineResources.html">Useful Online Resources</a>
			<a href = "safetyNotice.html">Safety Notice</a>
			<a href = "importantConcepts.html">Important Concepts</a>
			<a href = "componentsAndTools.html">Components and Tools</a>
		</div>
		
		<div class = "main">
			<h1>Understanding And Designing Guitar Effects Pedals</h1>
			<h2>A Beginners Guide</h2>
			
			<HR class = "orangeRow">

			<div id = "simplifyingAssumptions">
				<h3>Simplifying Assumptions</h3>
				<div id = "musicalNoteSimplification">
					<h4>'Pure' musical note simplification</h4>
					<p>
						You may know that each note you play on the guitar is dominated by its fundamental frequency [link], \(f_0\) and is accompanied by higher frequency (higher pitched) overtones (or harmonics [link]) occurring at integer multiples of the fundamental frequency (\(f_n=(n+1)×f_0\)) and are present with a lower amplitude than the fundamental frequency. All these components additively combine to create a single waveform (<a href = "https://en.wikipedia.org/wiki/Superposition_principle#Wave_superposition" target="_blank">superposition</a>). To put it another way, <b>the sound that we hear can be broken up into some number of sinusoidal waveforms of varying frequencies and amplitudes</b>. Figure 2 illustrates this with the bottom plot being a superposition of two waves with frequencies of \(110 Hz\) and \(220 Hz\).
					</p>
					<figure id = "figure2">
						<img src = "figures/additiveComboPlot.png" alt = "The superposition of two waves"></img>
						<figcaption>Fig. 2 - An illustration of the superposition of two waves</figcaption>
					</figure>
					<p>
					To help visualise all of this, an <a href = "https://www.audacityteam.org/" target="_blank">Audacity</a> analysis of an <a href = "https://archive.org/details/GuitarChord-A/5th_String_A.aiff" target="_blank">open A string recording</a> follows.
					</p>
					<p>
						Figure 3 shows a portion of the waveform of the recording. There is a general periodicity to the signal, though you can clearly see the shape of the wave changing over time. This is a result of the harmonic content of the note changing over time. The duration for 10 cycles of this waveform is measured to be \(T_{10}=0.091s\). Averaging this result over ten cycles gives the duration of a single cycle, \(T={T_{10} \over 10}=0.0091s\). Now, frequency is simply defined as \(f={1 \over T}\), and so the (dominant) frequency of this signal is \(f={1 \over 0.0091}≈110Hz\), as we expect for an open A string.
					</p>
					<p>
						Figure 4 shows the frequency analysis of this same audio signal (using Audacity’s Analyze > Plot Spectrum tool). This may or may not make sense to you, but the key points are that the horizontal axis represents frequency (in \(Hz\)), and the vertical axis represents the magnitude (in \(dB\)). Remember how we said we could split the audio signal into different frequency components - each with different magnitudes? This tool does that for us. In this case, the first 5 peaks are highlighted. They correspond to the fundamental frequency (\(f_0=110Hz\)), followed by the overtones we would expect for this note (\(f_1=220Hz\), \(f_2=330Hz\), \(f_3=440Hz\), \(f_4=550Hz\)).
					</p>
					<figure id = "figure3">
						<img src = "figures/A_String_waveform.png" alt = "An open A string recording, visualised (time domain)"></img>
						<figcaption>Fig. 3 - The waveform of an open 'A' string recording, as played on an acoustic guitar</figcaption>
					</figure>
					<figure id = "figure4">
						<img src = "figures/A_String_frequencyAnalysis.png" alt = "An open A string recording, visualised (frequency domain)"></img>
						<figcaption>Fig. 4 - The frequency spectrum of an open 'A' string recording, as played on an acoustic guitar</figcaption>
					</figure>
					<p>
						This might all make you a bit itchy… Especially with an eye on our future of trying to design a circuit that can manipulate this kind of signal in some way. Don’t worry. We will apply the following simplifications that should make things a lot easier:
						<ul>
							<li>Assume the audio signal is a perfect sinusoid.</li>
							<li>Assume the audio signal is of a single (fundamental) frequency, with no overtones. We will use \(f_0=110Hz\) as our default, which corresponds to the open A string.</li>
							<li>The amplitude of the signal remains constant over time, with no decay.</li>
						</ul>
					</p>
					<p>
						Figure 5 shows our simplified audio signal. Don’t worry about the much larger amplitude here – it’s simply been plotted with a peak amplitude of 1 for convenience. The frequency is still \(f_0=110Hz\), but we have eliminated the harmonics and any time variance in the signal. This will prove much simpler to analyse, and it turns out that it’s a good enough approximation to allow us to do a good job.
					</p>
					<figure id = "figure5">
						<img src = "figures/Idealised_waveform.png" alt = "An idealised 110Hz waveform"></img>
						<figcaption>Fig. 5 - A simplified audio signal waveform at \(110Hz\)</figcaption>
					</figure>
				</div>
				<div id = "signalFlowSimplification">
					<h4>Signal Flow Simplification</h4>
					<p>
						Focussing on a single pedal design at a time, we will assume the chain of events is as follows:
					</p>
					<p>
						Guitar Output > Effects Pedal > Amplifier Input
					</p>
					<p>
						We already touched on pickups, but for all that follows, they’re not an important part of the signal chain. The same is true at the other end, and we don’t really care what happens once the signal has entered the amplification stage. However, it is still important to consider the guitar output and the amplifier input as (perhaps surprisingly) they contain components which will actually effect how our pedal sounds, and impose some limits on our designs.
					</p>
				</div>
			</div>
			
		</div>
		
	</body>
</html>